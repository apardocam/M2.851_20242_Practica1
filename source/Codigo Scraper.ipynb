{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4188a487-d4e3-4592-988e-be7527b1a4f8",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c6da53",
   "metadata": {},
   "source": [
    "En este voy a dividir imdb score y rating y voy a intentar que funcione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a121dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (4.30.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b0490c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromedriver_autoinstaller in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (0.6.4)\n",
      "Requirement already satisfied: packaging>=23.1 in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (from chromedriver_autoinstaller) (24.2)\n"
     ]
    }
   ],
   "source": [
    "# Descarga automáticamente la versión correcta de chromedriver\n",
    "!pip install chromedriver_autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff92437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/anaconda3/envs/environment_uoc20242pec1/lib/python3.13/site-packages (5.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b733db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import chromedriver_autoinstaller\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2393c8",
   "metadata": {},
   "source": [
    "Empezamos por definir la funcion que abra el navegador y haga scroll down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec3b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peliculas(año):\n",
    "    # Importar las librerías necesarias\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from bs4 import BeautifulSoup as bs\n",
    "    import time\n",
    "\n",
    "    # Configuración del navegador\n",
    "    options = Options()\n",
    "    options.headless = False  # Se ejecuta con interfaz gráfica\n",
    "    service = Service()  # Se detecta automáticamente el ChromeDriver\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    # Abrir la URL con el año especificado\n",
    "    url = f\"https://www.justwatch.com/es/peliculas?release_year_from={año}&release_year_until={año}\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Esperar a que se muestre el cuadro de cookies\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Intentar acceder al shadow root y hacer click en \"Aceptar todas las cookies\"\n",
    "    try:\n",
    "        shadow_root = driver.execute_script(\"return arguments[0].shadowRoot\", driver.find_element(By.CSS_SELECTOR, \"#usercentrics-root\"))\n",
    "        time.sleep(1)\n",
    "        shadow_root.find_element(By.CSS_SELECTOR, \".sc-dcJsrY.dQaUXI\").click()\n",
    "    except Exception as e:\n",
    "        print(\"No se encontró o no se pudo aceptar las cookies:\", e)\n",
    "    \n",
    "    # Realizar scroll hasta el final de la página para cargar todo el contenido\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    \n",
    "    while True:\n",
    "        # Hacer scroll hasta el final de la página\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        try:\n",
    "            # Esperar a que la altura de la página cambie\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                lambda driver: driver.execute_script(\"return document.body.scrollHeight\") > last_height\n",
    "            )\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            last_height = new_height\n",
    "            \n",
    "        except Exception:\n",
    "            # En caso de no cargarse más contenido, intentar hacer scroll inverso y de nuevo hacia abajo\n",
    "            try:\n",
    "                iteration_count = 0\n",
    "                while iteration_count < 10:\n",
    "                    for _ in range(5):\n",
    "                        driver.execute_script(\"window.scrollBy(0, -400);\")\n",
    "                        time.sleep(0.5)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    \n",
    "                    WebDriverWait(driver, 3).until(\n",
    "                        lambda driver: driver.execute_script(\"return document.body.scrollHeight\") > last_height\n",
    "                    )\n",
    "                    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    \n",
    "                    if new_height == last_height:\n",
    "                        break\n",
    "                    last_height = new_height\n",
    "                    iteration_count += 1\n",
    "                    \n",
    "                if iteration_count == 10:\n",
    "            except Exception:\n",
    "            break\n",
    "\n",
    "    # Obtener el HTML de la página y procesarlo con BeautifulSoup\n",
    "    html = driver.page_source\n",
    "    soup = bs(html, 'html.parser')\n",
    "    \n",
    "    # Extraemos los títulos de las películas buscando las etiquetas 'a' con la clase 'title-list' y nos quedamos con los atributos 'href'\n",
    "    movie_titles = soup.find_all('a', class_='title-list-grid__item--link', attrs={'href': True})\n",
    "    movie_title_list = [movie['href'] for movie in movie_titles]\n",
    "\n",
    "    # Eliminar duplicados\n",
    "    movie_title_list_unique = list(set(movie_title_list))\n",
    "    print(\"Número de películas encontradas:\", len(movie_title_list_unique))\n",
    "        \n",
    "   \n",
    "    # Llamar a la función extractor para obtener los datos detallados de cada película\n",
    "    data = extractor(movie_title_list_unique)\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        \"title\": data[\"title\"],\n",
    "        \"year\": data[\"year\"],\n",
    "        \"platforms\": data[\"platforms\"],\n",
    "        \"jw_score\": data[\"jw_score\"],\n",
    "        \"jw_ratings\": data[\"jw_ratings\"],\n",
    "        \"imdb_score\": data[\"imdb_score\"],\n",
    "        \"imdb_ratings\": data[\"imdb_ratings\"],\n",
    "        \"genres\": data[\"genres\"],\n",
    "        \"duration\": data[\"duration\"],\n",
    "        \"ageRating\": data[\"ageRating\"],\n",
    "        \"countries\": data[\"countries\"]\n",
    "    })\n",
    "    \n",
    "    excel_file = f\"{año}.xlsx\"\n",
    "    df.to_excel(excel_file, index=False)\n",
    "\n",
    "    return 'Información Extraída'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a6a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(movie_title_list_unique):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup as bs\n",
    "    import time\n",
    "\n",
    "    # Inicialización de listas para almacenar la información\n",
    "    title = []\n",
    "    year = []\n",
    "    stream = []\n",
    "    platforms = []\n",
    "    jw_score = []\n",
    "    jw_ratings = []\n",
    "    imdb_score = []\n",
    "    imdb_ratings = []\n",
    "    genres_ = []\n",
    "    genres = []\n",
    "    duration = []\n",
    "    ageRating = []\n",
    "    countries_ = []\n",
    "    countries = []\n",
    "\n",
    "    # Usamos un user-agent para que la solicitud parezca provenir de un navegador real y evitar bloqueos\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Iteramos sobre la lista de títulos (enlaces)\n",
    "    for movie in movie_title_list_unique:\n",
    "        url = f\"https://www.justwatch.com{movie}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = bs(response.text, \"lxml\")\n",
    "\n",
    "        # Extraemos el título y el año\n",
    "        title_year = soup.find(\"h1\", class_=\"title-detail-hero__details__title\")\n",
    "        if title_year:\n",
    "            title_text = title_year.find(string=True, recursive=False)\n",
    "            if title_text:\n",
    "                title.append(title_text.strip())\n",
    "            else:\n",
    "                title.append(\"N/A\")\n",
    "            year_tag = title_year.find(\"span\", class_=\"release-year\")\n",
    "            if year_tag:\n",
    "                year.append(year_tag.text.strip())\n",
    "            else:\n",
    "                year.append(\"N/A\")\n",
    "        else:\n",
    "            title.append(\"N/A\")\n",
    "            year.append(\"N/A\")\n",
    "\n",
    "        # Extraemos las plataformas de streaming\n",
    "        offers_section = soup.find(\"div\", class_=\"buybox buybox-selector\")\n",
    "        if offers_section:\n",
    "            offer = offers_section.find(\"span\", class_=\"offer-container\")\n",
    "            if offer and offer.find(\"p\", class_=\"offer__label__text\"):\n",
    "                if offer.find(\"p\", class_=\"offer__label__text\").text == \"Suscripción\":\n",
    "                    stream.append(offer.find(\"img\")['alt'].strip())\n",
    "            platforms.append(stream)\n",
    "            stream = []  # Reiniciamos la lista de plataformas\n",
    "        else:\n",
    "            platforms.append([\"Nop\"])\n",
    "\n",
    "        # Extraemos las puntuaciones de JustWatch y IMDb\n",
    "        ratings = soup.find(\"div\", class_=\"jw-scoring-listing\")\n",
    "        if ratings:\n",
    "            areJWScore = ratings.find(\"div\", class_=\"jw-scoring-listing__rating--group jw-scoring-listing__rating--no-link\")\n",
    "            if areJWScore:\n",
    "                areJWScore2 = areJWScore.find(\"div\")\n",
    "                if areJWScore2:\n",
    "                    try:\n",
    "                        jw_score_, jw_ratings_ = areJWScore2.text.strip().split()\n",
    "                        jw_score.append(jw_score_)\n",
    "                        jw_ratings.append(jw_ratings_)\n",
    "                    except ValueError:\n",
    "                        jw_score.append(\"NOP\")\n",
    "                        jw_ratings.append(\"NOP\")\n",
    "                else:\n",
    "                    jw_score.append(\"NOP\")\n",
    "                    jw_ratings.append(\"NOP\")\n",
    "            else:\n",
    "                jw_score.append(\"NOP\")\n",
    "                jw_ratings.append(\"NOP\")\n",
    "            # IMDb (extraer score y ratings de forma similar)\n",
    "            areIMDbScore = ratings.find(\"div\", class_=\"jw-scoring-listing__rating--group jw-scoring-listing__rating--link\")\n",
    "            if areIMDbScore:\n",
    "                imdb_div = areIMDbScore.find(\"div\")\n",
    "                if imdb_div:\n",
    "                    try:\n",
    "                        imdb_score_, imdb_ratings_ = imdb_div.text.strip().split()\n",
    "                        imdb_score.append(imdb_score_)\n",
    "                        imdb_ratings.append(imdb_ratings_)\n",
    "                    except ValueError:\n",
    "                        imdb_score.append(\"NOP\")\n",
    "                        imdb_ratings.append(\"NOP\")\n",
    "                else:\n",
    "                    imdb_score.append(\"NOP\")\n",
    "                    imdb_ratings.append(\"NOP\")\n",
    "            else:\n",
    "                imdb_score.append(\"NOP\")\n",
    "                imdb_ratings.append(\"NOP\")\n",
    "        else:\n",
    "            jw_score.append(\"NOP\")\n",
    "            jw_ratings.append(\"NOP\")\n",
    "            imdb_score.append(\"NOP\")\n",
    "            imdb_ratings.append(\"NOP\")\n",
    "            \n",
    "        # Extraemos el género de la película\n",
    "        areGenres = soup.find('h3', class_='poster-detail-infos__subheading', string='Géneros')\n",
    "        if areGenres:\n",
    "            genres_ = areGenres.find_next_sibling('div', class_='poster-detail-infos__value').text.strip()\n",
    "            genres.append(genres_)\n",
    "        else:\n",
    "            genres.append(\"Nop\")\n",
    "\n",
    "        # Extraemos la duración de la película\n",
    "        isDuration = soup.find('h3', class_='poster-detail-infos__subheading', string='Duración')\n",
    "        if isDuration:\n",
    "            duration.append(isDuration.find_next_sibling('div', class_='poster-detail-infos__value').text.strip())\n",
    "        else:\n",
    "            duration.append(\"Nop\")\n",
    "\n",
    "        # Extraemos la clasificación por edades\n",
    "        isAgeRating = soup.find('h3', class_='poster-detail-infos__subheading', string='Clasificación por edades')\n",
    "        if isAgeRating:\n",
    "            ageRating.append(isAgeRating.find_next_sibling('div', class_='poster-detail-infos__value').text.strip())\n",
    "        else:\n",
    "            ageRating.append(0)\n",
    "\n",
    "        # Extraemos el país de producción\n",
    "        areCountries = soup.find('h3', class_='poster-detail-infos__subheading', string='País de producción')\n",
    "        if areCountries:\n",
    "            countries_ = areCountries.find_next_sibling('div', class_='poster-detail-infos__value').text.strip()\n",
    "            countries.append(countries_)\n",
    "        else:\n",
    "            countries.append(\"Nop\")\n",
    "\n",
    "        # Esperamos 0.5 segundos entre peticiones para no sobrecargar el servidor\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # Se retorna un diccionario con toda la información extraída\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"year\": year,\n",
    "        \"platforms\": platforms,\n",
    "        \"jw_score\": jw_score,\n",
    "        \"jw_ratings\": jw_ratings,\n",
    "        \"imdb_score\": imdb_score,\n",
    "        \"imdb_ratings\": imdb_ratings,\n",
    "        \"genres\": genres,\n",
    "        \"duration\": duration,\n",
    "        \"ageRating\": ageRating,\n",
    "        \"countries\": countries\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bbee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se alcanzó el límite de 10 iteraciones.\n",
      "Número de películas encontradas: 1900\n"
     ]
    }
   ],
   "source": [
    "peliculas(2023)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
